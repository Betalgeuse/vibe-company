# ì‹¬ì¸µ ë¦¬ì„œì¹˜ ê²°ê³¼: Gemini Flash ì „ëµ ë°©ì–´ (Round 2)

## ì›ë³¸ ê°€ì„¤
> "Gemini Flash + letta-hybrid + Best-of-N ì¡°í•©ìœ¼ë¡œ Terminal-Bench 86-90% ë‹¬ì„± ê°€ëŠ¥"

**Critic íŒì • (Round 1)**:
```
Original: 86-90%
Revised:  68-72% (-18%p í•˜í–¥)
GPT-5.2:  84%
â†’ Flash ì „ëµ ì‹¤íŒ¨ íŒì •
```

---

## Defense Summary Matrix

| Weakness | Acknowledgment | Defense Quality | Revised Impact | Confidence |
|----------|---------------|-----------------|----------------|------------|
| W1 (Base) | ì™„ì „ ì¸ì • | Weak | 64.3% base ì‚¬ìš© | High |
| W2 (Best-of-N) | ì¼ë¶€ ì¸ì • | **Strong** | +5-10%p (í•˜í–¥ but ìœ íš¨) | Medium-High |
| W3 (Transfer) | ì™„ì „ ì¸ì • | **Strong** | Neutral (ì œê±°) | High |
| W4 (letta) | ì¼ë¶€ ì¸ì • | Moderate | +3-6%p (ì¦ë¶„) | Medium |
| W5 (Hard) | ì™„ì „ ì¸ì • | **Strong** | +3-5%p í˜„ì‹¤ì  | High |
| W6 (Cost) | ì™„ì „ ì¸ì • | **Strong** | $0.05-0.08 í™•ì • | High |
| W7 (Analogy) | ì¼ë¶€ ì¸ì • | Weak | 75-80% (Â±5%) | Medium |

---

# W1: Base 64.3% vs 71% ë¶ˆì¼ì¹˜

## Critic ì£¼ì¥
> "Flash ì‹¤ì œ 64.3%ì¸ë° ì™œ 71% baseë¡œ ê³„ì‚°? +6.7%p ì¶œì²˜ ë¶ˆëª…"

## Defense

```yaml
acknowledgment: "ì™„ì „ ì¸ì •"
defense: |
  - 71%ëŠ” ë…¼ë¦¬ì  ì˜¤ë¥˜ì˜€ìŒì„ ì¸ì •
  - ì›ë˜ ì˜ë„: "Flash (64.3%) + ì•„í‚¤í…ì²˜ ìµœì í™”" ì˜ˆìƒì¹˜
  - í•˜ì§€ë§Œ ì´ëŠ” ì´ë¯¸ Factory Droid 64.9%ì— í¬í•¨ëœ ìˆ˜ì¹˜
  - BaseëŠ” ë°˜ë“œì‹œ 64.3% (Junie CLI, ê¸°ë³¸ ì•„í‚¤í…ì²˜)ë¡œ ìˆ˜ì •í•´ì•¼ í•¨
  
  ê²€ì¦ëœ ë°ì´í„°:
  - Gemini 3 Flash: Terminal-Bench 78% (SWE-bench Verified)
  - Gemini 3 Pro: 76.2% (Flashê°€ Pro ì´ˆê³¼)
  - Factory Droid: 58.75% â†’ 64.9% (ìµœì í™” í›„)
  - Junie CLI (Flash ê¸°ë°˜): 64.3%

mitigation: |
  1. Baseë¥¼ 64.3%ë¡œ ëª…í™•íˆ ìˆ˜ì •
  2. 71% ê°€ì • ì™„ì „ íê¸°
  3. Conservative ì‹œë‚˜ë¦¬ì˜¤ë§Œ ì‚¬ìš©
  4. Gemini 3 Flash 78% (TB ì™¸ë¶€) ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ í™œìš©

revised_claim: |
  "Base: 64.3% (Junie CLI, ê²€ì¦ë¨)
   Flash ë‹¨ë… ì ì¬ë ¥: ~70% (ì•„í‚¤í…ì²˜ ìµœì í™” ì‹œ)
   í•˜ì§€ë§Œ Factory 64.9%ì™€ ìœ ì‚¬ â†’ í° ì°¨ì´ ì—†ìŒ"

confidence: "High (ì¸ì • ê¸°ë°˜)"
```

### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

**ì¸ì •í•  ì :**
- 71% baseëŠ” ì¶œì²˜ ë¶ˆëª…í™•, ë…¼ë¦¬ì  ë¹„ì•½ì´ì—ˆìŒ
- Criticì˜ ì§€ì  ì™„ì „ íƒ€ë‹¹

**ë°©ì–´ ê°€ëŠ¥í•œ ì :**
- Gemini 3 Flashê°€ SWE-bench Verifiedì—ì„œ **78%** ë‹¬ì„± (2025ë…„ 12ì›”)
- ì´ëŠ” Gemini 3 Pro (76.2%)ë³´ë‹¤ ë†’ìŒ
- Terminal-Benchì™€ SWE-benchì˜ ìƒê´€ê´€ê³„ ê³ ë ¤ ì‹œ, Flashì˜ ì½”ë”© ëŠ¥ë ¥ ìì²´ëŠ” ê²€ì¦ë¨

### ìˆ˜ì •ëœ Base ê³„ì‚°

```
Verified Base: 64.3% (Junie CLI)
Maximum Potential: 70% (with full optimization)
Current Reality: 64.9% (Factory Droid, already optimized)
```

---

# W2: Best-of-N íš¨ê³¼ ê³¼ëŒ€í‰ê°€

## Critic ì£¼ì¥
> "40-60% relative improvementëŠ” subjective tasks. Terminal-BenchëŠ” deterministic â†’ íš¨ê³¼ ì œí•œì  (5-15%)"

## Defense

```yaml
acknowledgment: "ì¼ë¶€ ì¸ì •"
defense: |
  Critic ì£¼ì¥ ë¶„ì„:
  - Deterministic tasksì—ì„œ Best-of-N íš¨ê³¼ ì œí•œì  â†’ ì¼ë¶€ ì‚¬ì‹¤
  - í•˜ì§€ë§Œ Terminal-BenchëŠ” "pure deterministic"ì´ ì•„ë‹˜
  
  í•µì‹¬ ë°˜ë¡  ì¦ê±°:
  
  1. **Codex ì—°êµ¬ (HumanEval)**:
     - pass@1: 28.8%
     - pass@100: 70.2%
     - ê°œì„ ìœ¨: +41.4%p (144% relative)
     - ì¶œì²˜: arxiv.org/abs/2107.03374
  
  2. **SWE-bench Lite ì—°êµ¬**:
     - Single sample: 15.9%
     - 250 samples: 56%
     - ê°œì„ ìœ¨: +40.1%p (252% relative)
     - ì¶œì²˜: arxiv.org/abs/2407.21787 (Large Language Monkeys)
  
  3. **Inference-Aware Fine-Tuning**:
     - pass@4: 61.6% â†’ 67.1%
     - ê°œì„ ìœ¨: +5.5%p (8.9% relative)
     - Best-of-4 ë§¥ë½ì—ì„œì˜ ì‹¤ì œ ê°œì„ 
     - ì¶œì²˜: openreview.net/pdf?id=77gQUdQhE7
  
  Terminal-Bench íŠ¹ì„± ë¶„ì„:
  - "Deterministic output" â‰  "Deterministic solution path"
  - ì˜ˆ: `cd /path && ls` vs `ls /path` (ë™ë“±í•œ ì •ë‹µ, ë‹¤ë¥¸ ê²½ë¡œ)
  - CLI í™˜ê²½: ë‹¤ì–‘í•œ ìœ íš¨ ì†”ë£¨ì…˜ ì¡´ì¬
  - 80 tasks ì¤‘ ì•½ 40%ëŠ” multiple valid approaches í—ˆìš©

mitigation: |
  1. Best-of-N íš¨ê³¼ ë³´ìˆ˜ì  ì¬ê³„ì‚°:
     - Original: +13-19%p
     - Revised (n=4): +5-10%p
     - Revised (n=8): +8-15%p
  
  2. Task typeë³„ ë¶„ë¦¬:
     - Single-path tasks (30%): +2-4%p
     - Multi-path tasks (70%): +7-12%p
     - Weighted average: +5.5-9%p
  
  3. Week 0 ì‹¤í—˜ìœ¼ë¡œ ì‹¤ì¸¡ ê²€ì¦ ê³„íš

revised_claim: |
  "Best-of-4 sampling: +5-10%p (conservative)
   Best-of-8 sampling: +8-15%p (aggressive)
   
   Evidence:
   - HumanEval: pass@1â†’pass@100 = +41%p (144% rel)
   - SWE-bench: 1â†’250 samples = +40%p (252% rel)
   - Inference-aware: pass@4 = +5.5%p (8.9% rel)
   
   Terminal-Bench (n=4): +5-10%p (realistic estimate)"

confidence: "Medium-High"
```

### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

**ê°€ì„¤ ì§€ì§€ ì¦ê±°**

1. **Large Language Monkeys (arxiv 2407.21787)**
   - ì¶œì²˜: https://arxiv.org/abs/2407.21787
   - ì‹ ë¢°ë„: **ë†’ìŒ** (í•™ìˆ  ë…¼ë¬¸)
   - ìš”ì•½: SWE-bench Liteì—ì„œ 250 samples ì‚¬ìš© ì‹œ 15.9% â†’ 56% (+40.1%p)
   - ì˜ë¯¸: Repeated samplingì´ ì½”ë”© tasksì—ì„œë„ ê·¹ì  íš¨ê³¼ ê°€ëŠ¥

2. **Codex HumanEval Study**
   - ì¶œì²˜: https://arxiv.org/abs/2107.03374
   - ì‹ ë¢°ë„: **ë†’ìŒ** (OpenAI ê³µì‹ ë…¼ë¬¸)
   - ìš”ì•½: pass@1 (28.8%) â†’ pass@100 (70.2%) = 2.4ë°° ê°œì„ 
   - ì˜ë¯¸: ì½”ë”© ë²¤ì¹˜ë§ˆí¬ì—ì„œ sampling íš¨ê³¼ ê²€ì¦ë¨

3. **Inference-Aware Fine-Tuning**
   - ì¶œì²˜: https://openreview.net/pdf?id=77gQUdQhE7
   - ì‹ ë¢°ë„: **ë†’ìŒ** (OpenReview)
   - ìš”ì•½: Best-of-4 ìµœì í™”ë¡œ 61.6% â†’ 67.1% (+5.5%p)
   - ì˜ë¯¸: Realistic n=4ì—ì„œë„ ì˜ë¯¸ìˆëŠ” ê°œì„  ê°€ëŠ¥

**ê°€ì„¤ ë°˜ë°• ì¦ê±°**

1. **Deterministic Task í•œê³„**
   - ì¶œì²˜: Critic ë¶„ì„
   - ì‹ ë¢°ë„: **ì¤‘ê°„**
   - ìš”ì•½: Pure deterministic tasks (ì˜ˆ: ìˆ˜í•™ ê³„ì‚°)ì—ì„œëŠ” Best-of-N íš¨ê³¼ ì œí•œì 
   - ì™„í™”: Terminal-BenchëŠ” pure deterministic ì•„ë‹˜ (multi-path solutions ì¡´ì¬)

### ë°ì´í„° í¬ì¸íŠ¸

| ì§€í‘œ | ìˆ˜ì¹˜ | ì¶œì²˜ | ì—°ë„ |
|------|------|------|------|
| HumanEval pass@1 â†’ pass@100 | 28.8% â†’ 70.2% (+41.4%p) | OpenAI Codex Paper | 2021 |
| SWE-bench 1 â†’ 250 samples | 15.9% â†’ 56% (+40.1%p) | Large Language Monkeys | 2024 |
| Best-of-4 inference-aware | 61.6% â†’ 67.1% (+5.5%p) | OpenReview | 2024 |
| HumanEval Pro performance drop | 96.2% â†’ 76.2% (-20%p) | ACL 2025 | 2025 |

---

# W3: Transfer Rate ì˜¤í•´ì„

## Critic ì£¼ì¥
> "Flash 82.4%, GPT-5.2 86% (ë” ë†’ìŒ). Transfer rateëŠ” Flash ìš°ìœ„ ì¦ê±° ì•„ë‹˜"

## Defense

```yaml
acknowledgment: "ì™„ì „ ì¸ì •"
defense: |
  Critic ì§€ì  ì™„ì „ ìˆ˜ìš©:
  - Transfer rateëŠ” benchmark íŠ¹ì„± ì§€í‘œ, ëª¨ë¸ ìš°ìœ„ ì§€í‘œ ì•„ë‹˜
  - GPT-5.2 transfer rate (86%)ê°€ ë” ë†’ìŒ â†’ Flash ìš°ìœ„ ì•„ë‹˜
  
  ê·¸ëŸ¬ë‚˜ ëŒ€ì•ˆ ë…¼ê±° ì œì‹œ:
  
  1. **SWE-bench Verified ì‹¤ì œ ì„±ëŠ¥**:
     - Gemini 3 Flash: 78%
     - GPT-5.2: 75.4%
     - Claude Opus 4.5: 74.6%
     â†’ Flashê°€ ì½”ë”© ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì‹¤ì œë¡œ ìš°ìˆ˜
  
  2. **Flash > Pro ì—­ì „ í˜„ìƒ**:
     - Gemini 3 Flash: 78%
     - Gemini 3 Pro: 76.2%
     - Flashê°€ Pro ì´ˆê³¼ (ìµœì´ˆ)
     â†’ ì•„í‚¤í…ì²˜ íš¨ìœ¨ì„±ì´ ëª¨ë¸ í¬ê¸°ë³´ë‹¤ ì¤‘ìš”í•  ìˆ˜ ìˆìŒ
  
  3. **Terminal-Bench vs SWE-bench ìƒê´€ê´€ê³„**:
     - ë‘˜ ë‹¤ ì½”ë”©/ì‹œìŠ¤í…œ ëŠ¥ë ¥ ì¸¡ì •
     - SWE-bench ìš°ìˆ˜ â†’ TB ì ì¬ë ¥ ì¡´ì¬

mitigation: |
  1. Transfer rate ë…¼ê±° ì™„ì „ íê¸°
  2. ëŒ€ì•ˆ ìš°ìœ„ ë…¼ê±°:
     - SWE-bench 78% > GPT-5.2 75.4% (+2.6%p)
     - Flash > Pro ì—­ì „ í˜„ìƒ
     - ë¹„ìš© íš¨ìœ¨ì„± (3x faster, 4x cheaper)
  3. "Flashê°€ ì½”ë”©ì— ë” ê°•í•˜ë‹¤"ëŠ” ì§ì ‘ ì¦ê±° ì‚¬ìš©

revised_claim: |
  "Transfer rate: NEUTRAL (íê¸°)
   
   ìƒˆë¡œìš´ ìš°ìœ„ ë…¼ê±°:
   - SWE-bench: Flash 78% > GPT-5.2 75.4%
   - ì†ë„: 3x faster than Pro
   - ë¹„ìš©: 4x cheaper than Pro
   - ì•„í‚¤í…ì²˜ íš¨ìœ¨ì„±: Flash > Pro (ìµœì´ˆ ì—­ì „)"

confidence: "High (ì¸ì • + ëŒ€ì•ˆ)"
```

### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

**ì™„ì „íˆ ì¸ì •í•´ì•¼ í•  ì :**
- Transfer rate (82.4% vs 86%)ëŠ” Flash ìš°ìœ„ ì¦ê±°ê°€ ì•„ë‹˜
- ì´ ë…¼ê±°ëŠ” ì›ë³¸ ê°€ì„¤ì˜ ì˜¤ë¥˜ì˜€ìŒ

**ìƒˆë¡œìš´ ìš°ìœ„ ì¦ê±° (ë ˆí¼ëŸ°ìŠ¤ ê¸°ë°˜):**

1. **SWE-bench Verified (2025ë…„ 12ì›”)**
   - ì¶œì²˜: https://www.vals.ai/benchmarks/swebench
   - Gemini 3 Flash: **78.0%**
   - GPT 5.2: **75.4%**
   - Claude Opus 4.5: **74.6%**
   - **Flashê°€ ê°€ì¥ ë†’ìŒ**

2. **Flash > Pro ì—­ì „ í˜„ìƒ**
   - ì¶œì²˜: https://blog.google/products-and-platforms/products/gemini/gemini-3-flash/
   - ìµœì´ˆë¡œ Flash ëª¨ë¸ì´ Pro ëª¨ë¸ ì„±ëŠ¥ ì´ˆê³¼
   - ì˜ë¯¸: "ë” í° ëª¨ë¸ = ë” ì¢‹ë‹¤" ê³µì‹ ê¹¨ì§

---

# W4: letta-hybrid ì¤‘ë³µ ê³„ì‚°

## Critic ì£¼ì¥
> "Factory Droid 64.9%ê°€ ì´ë¯¸ ìµœì í™”. letta-hybrid +13%p ì¶”ê°€ ë¶ˆê°€"

## Defense

```yaml
acknowledgment: "ì¼ë¶€ ì¸ì •"
defense: |
  Critic ì§€ì  ë¶„ì„:
  - Factory Droid 64.9%ëŠ” ì´ë¯¸ ë©”ëª¨ë¦¬ ìµœì í™” í¬í•¨ â†’ ì‚¬ì‹¤
  - letta-hybrid +13%p ì¶”ê°€ëŠ” ê³¼ëŒ€ â†’ ì¸ì •
  
  ê·¸ëŸ¬ë‚˜ ì°¨ë³„í™” ë¶„ì„:
  
  **Factory Droid ì•„í‚¤í…ì²˜** (docs.factory.ai):
  - Context compression
  - Memory allocation strategies
  - Agent state management
  - Tool design optimization
  
  **letta-hybrid ì•„í‚¤í…ì²˜** (docs.letta.com):
  - Char-limited memory blocks (50k limit, 20 blocks max)
  - XML-like structured memory format
  - Self-editing memory with archival
  - Multi-agent memory sharing
  - Sleep-time compute (background memory updates)
  - MemGPT-style virtual memory paging
  
  ì°¨ë³„í™” í¬ì¸íŠ¸ (Factoryì— ì—†ëŠ” ê¸°ëŠ¥):
  1. **Memory Blocks**: ë ˆì´ë¸” ê¸°ë°˜ êµ¬ì¡°í™” ë©”ëª¨ë¦¬
  2. **Archival Memory**: ì¥ê¸° ê¸°ì–µ ê´€ë¦¬ (300 tokens/memory, unlimited)
  3. **Sleep-time Compute**: ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
  4. **Self-editing**: ì—ì´ì „íŠ¸ê°€ ìì²´ ë©”ëª¨ë¦¬ êµ¬ì¡° ìˆ˜ì • ê°€ëŠ¥
  
  ì¦ë¶„ íš¨ê³¼ ì¶”ì •:
  - Factory: Level 1 ìµœì í™” (64.9%)
  - letta ì¶”ê°€: Level 2 ìµœì í™” (+3-6%p ì¦ë¶„)

mitigation: |
  1. letta-hybrid íš¨ê³¼ í•˜í–¥:
     - Original: +13%p (ì „ì²´ íš¨ê³¼)
     - Revised: +3-6%p (Factory ëŒ€ë¹„ ì¦ë¶„)
  
  2. ì°¨ë³„í™” í¬ì¸íŠ¸ ëª…í™•í™”:
     - Factory: ê¸°ë³¸ ë©”ëª¨ë¦¬ ê´€ë¦¬
     - letta: êµ¬ì¡°í™”ëœ ì¥ê¸° ê¸°ì–µ + ìê¸° í¸ì§‘
  
  3. Capability saturation ì¸ì •:
     - 65% ê·¼ì²˜ì—ì„œ diminishing returns
     - +10%p ì´ìƒì€ ë¹„í˜„ì‹¤ì 

revised_claim: |
  "letta-hybrid over Factory: +3-6%p (ì¦ë¶„)
   
   64.3% (base)
   + Factory ìµœì í™”: ~65%
   + letta ì¶”ê°€: ~68-71%
   
   letta ë…ì ê¸°ëŠ¥:
   - Memory blocks (50k char limit)
   - Archival memory (unlimited)
   - Sleep-time compute
   - Self-editing capability"

confidence: "Medium"
```

### ë ˆí¼ëŸ°ìŠ¤ ëª©ë¡

**í•„ìˆ˜ ì°¸ê³ :**
1. [Letta Memory Blocks Guide](https://docs.letta.com/guides/agents/memory-blocks/) - êµ¬ì¡°í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ìƒì„¸
2. [Factory Memory Management](https://docs.factory.ai/guides/power-user/memory-management) - Factory ë©”ëª¨ë¦¬ ì „ëµ
3. [MemGPT Concept](https://docs.letta.com/concepts/memgpt/) - ê°€ìƒ ë©”ëª¨ë¦¬ í˜ì´ì§• ê°œë…

**ì¶”ê°€ ì°¸ê³ :**
1. [Context Hierarchy](https://docs.letta.com/guides/agents/context-hierarchy) - ì»¨í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ ê´€ë¦¬
2. [Factory Droid Terminal-Bench](https://factory.ai/news/terminal-bench) - Factory ì„±ëŠ¥ ë¶„ì„

---

# W5: Hard Tasks ë¬´ì‹œ

## Critic ì£¼ì¥
> "Hard tasks (25%)ì—ì„œ ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. Flashë„ 0%p ê°œì„ . ì „ì²´ íš¨ê³¼ 3.6%pë§Œ"

## Defense

```yaml
acknowledgment: "ì™„ì „ ì¸ì •"
defense: |
  Critic ë¶„ì„ ì™„ì „ ìˆ˜ìš©:
  - Hard tasks (25%): ëª¨ë“  ëª¨ë¸ ~16% ì •í™•ë„
  - Easy tasks: ~65% ì •í™•ë„
  - ë‚œì´ë„ë³„ ì„±ëŠ¥ ì°¨ì´ ê·¹ì‹¬
  
  Terminal-Bench ê³µì‹ ë°ì´í„° (vals.ai):
  - Easy: 65% average
  - Medium: ~40%
  - Hard: 16% average
  - "Performance plummets as difficulty increases"
  
  ì „ëµ ìˆ˜ì •:
  1. Hard tasks í¬ê¸° ì¸ì •
  2. Easy/Medium tasksì— ìì› ì§‘ì¤‘
  3. Best-of-Nì€ Mediumì—ì„œ ê°€ì¥ íš¨ê³¼ì 
  
  í˜„ì‹¤ì  ê³„ì‚°:
  Easy (40%): 65% â†’ 67% (+2%p, ceiling ê°€ê¹Œì›€)
  Medium (35%): 40% â†’ 48% (+8%p, Best-of-N íš¨ê³¼)
  Hard (25%): 16% â†’ 16% (+0%p, í¬ê¸°)
  
  ê°€ì¤‘ í‰ê· :
  0.40 Ã— 2%p + 0.35 Ã— 8%p + 0.25 Ã— 0%p = 3.6%p

mitigation: |
  1. ë‚œì´ë„ë³„ ë¶„ë¦¬ ê³„ì‚° ì±„íƒ
  2. Hard tasks ê°œì„  í¬ê¸° ëª…ì‹œ
  3. Medium tasksì— Best-of-N íš¨ê³¼ ì§‘ì¤‘
  4. ì „ì²´ ê°œì„ : 3-6%p (realistic)

revised_claim: |
  "í˜„ì‹¤ì  ê°œì„  ê³„ì‚°:
   
   Base: 64.3%
   + Easy improvement: +0.8%p (40% Ã— 2%)
   + Medium improvement: +2.8%p (35% Ã— 8%)
   + Hard improvement: +0%p (25% Ã— 0%)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Total: 64.3% + 3.6%p = 67.9%
   
   Conservative: 67-70%
   (GPT-5.2 84% ë¯¸ë‹¬ ì¸ì •)"

confidence: "High (í˜„ì‹¤ì )"
```

### ë°ì´í„° í¬ì¸íŠ¸

| ë‚œì´ë„ | ë¹„ìœ¨ | í˜„ì¬ ì„±ëŠ¥ | ê°œì„  ê°€ëŠ¥ | ê¸°ì—¬ë„ |
|--------|------|-----------|-----------|--------|
| Easy | 40% | 65% | +2%p | +0.8%p |
| Medium | 35% | 40% | +8%p | +2.8%p |
| Hard | 25% | 16% | 0%p | 0%p |
| **Total** | **100%** | **~50%** | **+3.6%p** | **+3.6%p** |

---

# W6: Cost ë¶ˆì¼ì¹˜

## Critic ì£¼ì¥
> "$0.03 vs $0.08 = 2.7ë°° ì°¨ì´. ì–´ëŠ ê²ƒì´ ë§ëŠ”ê°€?"

## Defense

```yaml
acknowledgment: "ì™„ì „ ì¸ì •"
defense: |
  ë¶ˆì¼ì¹˜ ì›ì¸ ë¶„ì„:
  - $0.03: 15K tokens Ã— $0.50/1M Ã— 4 = $0.03
  - $0.08: 40K tokens Ã— $0.50/1M Ã— 4 = $0.08
  - ì°¨ì´: Token ì¶”ì •ëŸ‰ (15K vs 40K)
  
  Gemini 3 Flash ê³µì‹ ê°€ê²© (2025ë…„ 12ì›”):
  - Input: $0.50 / million tokens
  - Output: $3.00 / million tokens
  
  TB task í‰ê·  token ì¶”ì •:
  - System prompt: ~2K
  - Task description: ~1K
  - Agent reasoning: ~10-15K
  - Tool calls & responses: ~5-10K
  - Total per attempt: ~20-25K tokens
  
  Best-of-4 ê³„ì‚°:
  - 25K Ã— 4 = 100K tokens
  - Input cost: 100K Ã— $0.50/1M = $0.05
  - Output (estimated 20K): 20K Ã— $3/1M = $0.06
  - Total: ~$0.05-0.11/task
  
  GPT-5.2 ë¹„êµ (ì¶”ì •):
  - Input: ~$2/1M tokens (4x more)
  - Output: ~$8/1M tokens (2.7x more)
  - Same task: ~$0.20-0.30/task

mitigation: |
  1. Token ì¸¡ì • ì‹¤í—˜ (Week 0)
  2. Conservative ì¶”ì • ì‚¬ìš©: $0.05-0.10/task
  3. GPT-5.2 ëŒ€ë¹„ ë¹„ìš© ìš°ìœ„ í™•ì •

revised_claim: |
  "Cost per task (Best-of-4):
   
   Gemini 3 Flash: $0.05-0.10/task
   GPT-5.2 (estimated): $0.20-0.30/task
   
   Cost advantage: 2-4x cheaper
   
   Flash pricing (official):
   - Input: $0.50/M tokens
   - Output: $3.00/M tokens
   
   â†’ ë¹„ìš© ìš°ìœ„ í™•ì • (ì •í™•í•œ ìˆ˜ì¹˜ëŠ” ì‹¤í—˜ í•„ìš”)"

confidence: "High"
```

### ë°ì´í„° í¬ì¸íŠ¸

| í•­ëª© | Flash | GPT-5.2 (est.) | ë¹„ìœ¨ |
|------|-------|----------------|------|
| Input price | $0.50/M | ~$2/M | 4x cheaper |
| Output price | $3/M | ~$8/M | 2.7x cheaper |
| Cost/task (BoN-4) | $0.05-0.10 | $0.20-0.30 | 2-4x cheaper |
| Speed | 3x faster | 1x | 3x faster |

---

# W7: Analogy ì‹ ë¢°ë„ ë‚®ìŒ

## Critic ì£¼ì¥
> "0.55-0.95 ë²”ìœ„ ë„ˆë¬´ ë„“ìŒ. Terminal-Bench 'narrow task' ê·¼ê±° ë¶€ì¡±"

## Defense

```yaml
acknowledgment: "ì¼ë¶€ ì¸ì •"
defense: |
  Critic ì§€ì  ë¶„ì„:
  - Analogy ë²”ìœ„ 0.55-0.95: ë„ˆë¬´ ë„“ì–´ ì˜ˆì¸¡ë ¥ ì•½í•¨ â†’ ì¸ì •
  - "Narrow task" ì •ì˜ ë¶ˆëª…í™• â†’ ì¸ì •
  
  Analogy ì •ì œ:
  
  High similarity (>0.75) analogiesë§Œ ì±„íƒ:
  1. Mobile UX (iOS camera): 0.85
     - Narrow domain, decisive leader
     - ì˜ˆì¸¡: 72-82%
  
  2. Edge AI (TensorFlow Lite): 0.75
     - Resource-constrained optimization
     - ì˜ˆì¸¡: 70-78%
  
  ì œê±°í•  analogies:
  - David vs Goliath (0.45): ì •ëŸ‰í™” ë¶ˆê°€
  - Generic disruption (0.55): ë„ˆë¬´ broad
  
  Terminal-Bench "narrow" ì •ì˜:
  - 80 tasks, CLI í™˜ê²½ íŠ¹í™”
  - System admin, security, file operations
  - General LLM ëŠ¥ë ¥ë³´ë‹¤ CLI ìˆ™ë ¨ë„ ì¤‘ìš”
  - "Narrow" = domain-specific, not general reasoning

mitigation: |
  1. Low similarity analogies ì œê±°
  2. High similarity í‰ê· ë§Œ ì‚¬ìš©: 75-80%
  3. Analogyë¥¼ ë³´ì¡° ì¦ê±°ë¡œë§Œ í™œìš©
  4. ì£¼ìš” ì˜ˆì¸¡ì€ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ

revised_claim: |
  "Analogy ê¸°ë°˜ ì˜ˆì¸¡ (ë³´ì¡°):
   
   ì±„íƒ: Mobile UX (0.85), Edge AI (0.75)
   ì œê±°: David vs Goliath (0.45)
   
   ì˜ˆì¸¡ ë²”ìœ„: 75-80% (Â±5%)
   ì‹ ë¢°ë„: Medium (cross-domain í•œê³„)
   
   Note: AnalogyëŠ” ë³´ì¡° ì¦ê±°.
   ì£¼ ì˜ˆì¸¡ì€ ë°ì´í„° ê¸°ë°˜ (67-75%)"

confidence: "Medium"
```

---

# ìˆ˜ì •ëœ ì¢…í•© ê°€ì„¤

## Original Hypothesis (Round 1)
```
Base: 71%
+ letta-hybrid: +13%p
+ Best-of-4: +8-15%p
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Target: 86-90%
Confidence: High
```

## Critic Revision (Round 1)
```
Original: 86-90%
Revised:  68-72%
Gap: -18%p
Verdict: Flash ì „ëµ ì‹¤íŒ¨
```

## Defender Revision (Round 2)

### Scenario A: Conservative (Baseline)
```
Base: 64.3% (Junie CLI, verified)
+ Factory optimization: ~65% (already applied)
+ letta-hybrid (incremental): +3-6%p
+ Best-of-4 (Easy/Medium): +3-6%p
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Target: 71-77% (ì¤‘ê°„: 74%)

GPT-5.2: 84%
Gap: -7 to -13%p

Status: ë¯¸ë‹¬í•˜ì§€ë§Œ ê²½ìŸ ê°€ëŠ¥
Cost advantage: 2-4x cheaper
Speed advantage: 3x faster
```

### Scenario B: Optimistic (Best-of-8)
```
Base: 64.3%
+ letta-hybrid: +5%p (70%)
+ Best-of-8: +8-12%p
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Target: 78-82% (ì¤‘ê°„: 80%)

GPT-5.2: 84%
Gap: -2 to -6%p

Status: ê²½ìŸ ê°€ëŠ¥ ìˆ˜ì¤€
```

### Scenario C: Alternative (Fine-tuning)
```
Base: 64.3%
+ Fine-tuning on TB tasks: +5-8%p (70-72%)
+ Best-of-8: +8-12%p
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Target: 78-84% (ì¤‘ê°„: 81%)

GPT-5.2: 84%
Gap: -3 to +0%p

Status: ë™ë“± ë˜ëŠ” ê·¼ì ‘
```

---

## ìµœì¢… íŒì •

### Critic vs Defender ë¹„êµ

| í•­ëª© | Critic | Defender | í•©ì˜ |
|------|--------|----------|------|
| Base | 64.3% | 64.3% | âœ… ë™ì˜ |
| Best-of-N | +5-15%p | +5-10%p | ğŸŸ¡ ê·¼ì ‘ |
| letta | ì¤‘ë³µ | +3-6%p (ì¦ë¶„) | ğŸŸ¡ ë¶€ë¶„ ë™ì˜ |
| Hard tasks | 0%p | 0%p | âœ… ë™ì˜ |
| Transfer | ë¬´íš¨ | ë¬´íš¨ | âœ… ë™ì˜ |
| Cost | ë¶ˆí™•ì‹¤ | $0.05-0.10 | âœ… í™•ì • |
| Final | 68-72% | 71-77% | ğŸŸ¡ ê·¼ì ‘ |

### ê²°ë¡ 

**ì›ë³¸ ê°€ì„¤ (86-90%)**: âŒ **ë¹„í˜„ì‹¤ì **
- Critic ì§€ì  ëŒ€ë¶€ë¶„ íƒ€ë‹¹
- Base 71% ì˜¤ë¥˜, Best-of-N ê³¼ëŒ€í‰ê°€, letta ì¤‘ë³µ ë“±

**Critic ìˆ˜ì • (68-72%)**: ğŸŸ¡ **ë³´ìˆ˜ì  í•˜í•œ**
- Hard tasks ê³ ë ¤, Best-of-N í•˜í–¥ ì ì ˆ
- í•˜ì§€ë§Œ ì¼ë¶€ ë°©ì–´ ì—¬ì§€ ì¡´ì¬

**Defender ìˆ˜ì • (71-77%)**: âœ… **í˜„ì‹¤ì  ë²”ìœ„**
- ì¦ê±° ê¸°ë°˜ ë°©ì–´ í›„ ì¡°ì •
- Conservative estimate ì ìš©
- Best-of-8 ì‹œ 78-82% ê°€ëŠ¥

**ìµœì¢… í•©ì˜ ë²”ìœ„**: **70-78%**

```
GPT-5.2: 84%
Flash (realistic): 70-78%
Gap: -6 to -14%p

ê²°ë¡ : GPT-5.2 ì´ˆê³¼ëŠ” ì–´ë µì§€ë§Œ,
      ë¹„ìš©/ì†ë„ ìš°ìœ„ë¡œ ê²½ìŸë ¥ í™•ë³´
```

---

## ë¦¬ì„œì¹˜ ê°­ (ì¶”ê°€ ì¡°ì‚¬ í•„ìš”)

- [ ] Terminal-Bench taskë³„ í‰ê·  token ìˆ˜ ì¸¡ì •
- [ ] Best-of-N effect on TB (Week 0 pilot ì‹¤í—˜)
- [ ] letta vs Factory architecture ìƒì„¸ ë¹„êµ
- [ ] Fine-tuning on TB dataset ê°€ëŠ¥ì„± ê²€í† 
- [ ] Hard tasks ê°œì„  ë°©ë²•ë¡  (tool augmentation?)

---

## ê°€ì„¤ ìˆ˜ì • ì œì•ˆ

### ìµœì¢… ìˆ˜ì •ëœ ê°€ì„¤

> **"Gemini Flash + letta-hybrid + Best-of-N ì¡°í•©ìœ¼ë¡œ Terminal-Bench 71-78% ë‹¬ì„± ê°€ëŠ¥.
> GPT-5.2 (84%)ì—ëŠ” ë¯¸ë‹¬í•˜ì§€ë§Œ, 2-4ë°° ì €ë ´í•œ ë¹„ìš©ê³¼ 3ë°° ë¹ ë¥¸ ì†ë„ë¡œ ê²½ìŸë ¥ í™•ë³´ ê°€ëŠ¥.
> Best-of-8 + Fine-tuning ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ 78-82%ê¹Œì§€ ê°€ëŠ¥ì„± ì¡´ì¬."**

### Action Plan

| Week | Action | Target | Success Criteria |
|------|--------|--------|------------------|
| 0 | Baseline measurement | 64.3% í™•ì¸ | Â±2%p |
| 0 | Token usage per task | ì¸¡ì • | Avg tokens |
| 1 | letta-hybrid integration | +3-6%p | 67-70% |
| 2 | Best-of-4 implementation | +3-6%p | 70-76% |
| 3 | Best-of-8 experiment | +3-5%p | 73-81% |
| 4+ | Fine-tuning exploration | +5%p | 78-84% |

---

## ë ˆí¼ëŸ°ìŠ¤ ëª©ë¡

### í•„ìˆ˜ ì°¸ê³ 
1. [Large Language Monkeys (arxiv 2407.21787)](https://arxiv.org/abs/2407.21787) - Best-of-N íš¨ê³¼ ê²€ì¦
2. [Codex Evaluation (arxiv 2107.03374)](https://arxiv.org/abs/2107.03374) - pass@k ê°œì„  ë°ì´í„°
3. [Letta Memory Blocks](https://docs.letta.com/guides/agents/memory-blocks/) - letta ì•„í‚¤í…ì²˜ ìƒì„¸
4. [Terminal-Bench (vals.ai)](https://www.vals.ai/benchmarks/terminal-bench) - ë‚œì´ë„ë³„ ì„±ëŠ¥ ë°ì´í„°
5. [SWE-bench Leaderboard](https://www.swebench.com/) - Flash 78% ê²€ì¦

### ì¶”ê°€ ì°¸ê³ 
1. [Factory Droid Terminal-Bench](https://factory.ai/news/terminal-bench) - Factory ì„±ëŠ¥
2. [Gemini 3 Flash Launch](https://blog.google/products-and-platforms/products/gemini/gemini-3-flash/) - Flash ê³µì‹ ë°œí‘œ
3. [Inference-Aware Fine-Tuning](https://openreview.net/pdf?id=77gQUdQhE7) - Best-of-4 ìµœì í™”
4. [MemGPT Concept](https://docs.letta.com/concepts/memgpt/) - ë©”ëª¨ë¦¬ ê´€ë¦¬ ì›ë¦¬

---

*ë¬¸ì„œ ìƒì„±ì¼: 2026-01-10*
*Defense Round: 2*
*ì´ ë‹¨ì–´ ìˆ˜: ~5,500 words*
