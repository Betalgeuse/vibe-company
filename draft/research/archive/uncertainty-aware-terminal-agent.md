# ë¦¬ì„œì¹˜ ì£¼ì œ: Uncertainty-Aware Terminal Agent

## ê°€ì„¤

> **"LLMì˜ í† í° í™•ë¥  ë¶„í¬(logprobs)ë¥¼ í™œìš©í•œ ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œì„ Terminal Agentì— ì ìš©í•˜ë©´, ê¸°ì¡´ ì „ëžµ ëŒ€ë¹„ ë…ë¦½ì ìœ¼ë¡œ +5-8% ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•  ìˆ˜ ìžˆë‹¤"**

### ê°€ì„¤ ì„¸ë¶€ ë¶„í•´
1. **Best-of-N ìµœì í™”**: Self-Certainty ê¸°ë°˜ ì‘ë‹µ ì„ íƒìœ¼ë¡œ +3-5% í–¥ìƒ
2. **Action Routing**: ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ë™ì  ê²½ë¡œ ì„ íƒìœ¼ë¡œ +2-3% í–¥ìƒ
3. **Backtracking ê°œì„ **: ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ í™•ë¥  íƒìƒ‰ìœ¼ë¡œ +2-4% í–¥ìƒ

---

## ë°°ê²½

### ì™œ ì´ ì£¼ì œì¸ê°€?

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸**: LLMì€ ë§¤ í† í° ìƒì„± ì‹œ í™•ë¥  ë¶„í¬(logprobs)ë¥¼ ê³„ì‚°í•˜ì§€ë§Œ, ëŒ€ë¶€ë¶„ì˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì´ ì •ë³´ë¥¼ ë²„ë¦¼

```
í† í° ìƒì„± ì‹œ ë‚´ë¶€ ìƒíƒœ:
â”œâ”€â”€ "git" â†’ 0.75 (ì„ íƒë¨)
â”œâ”€â”€ "cd"  â†’ 0.15
â”œâ”€â”€ "ls"  â†’ 0.08
â””â”€â”€ "rm"  â†’ 0.02
```

ì´ í™•ë¥  ì •ë³´ í™œìš© ì‹œ:
- **í™•ë¥  ë¶„ì‚°** (entropy ë†’ìŒ) â†’ "ë¶ˆí™•ì‹¤" â†’ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ ë˜ëŠ” ê²€ì¦
- **í™•ë¥  ì§‘ì¤‘** (entropy ë‚®ìŒ) â†’ "í™•ì‹ " â†’ ë°”ë¡œ ì‹¤í–‰
- **ì‹¤íŒ¨ í›„** â†’ ë‘ ë²ˆì§¸/ì„¸ ë²ˆì§¸ í™•ë¥ ì˜ ëŒ€ì•ˆ íƒìƒ‰

### í˜„ìž¬ ìƒí™©ì€?

| ìˆœìœ„ | Agent | ì •í™•ë„ |
|------|-------|--------|
| 1 | Factory Droid | 64.9% |
| 2 | Ante | 64.7% |
| 3 | Junie CLI | 64.3% |

**Gap**: 1ìœ„ì™€ 2ìœ„ ì°¨ì´ê°€ 0.2%ì— ë¶ˆê³¼ â†’ ìž‘ì€ ê°œì„ ë„ ìˆœìœ„ ë³€ë™ ê°€ëŠ¥

### ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ í•œê³„ëŠ”?

| ê¸°ì¡´ ì ‘ê·¼ë²• | í•œê³„ì  |
|-------------|--------|
| **Self-Consistency** | ë‹¤ìˆ˜ê²° ê¸°ë°˜, ì—°ì† ì ìˆ˜ ë¯¸í™œìš© |
| **Reward Models** | ì¶”ê°€ ëª¨ë¸ í•„ìš”, ê³„ì‚° ë¹„ìš© ë†’ìŒ |
| **ë‹¨ìˆœ Temperature** | ë¶ˆí™•ì‹¤ì„± ë¶„í¬ ë¬´ì‹œ |
| **ê³ ì • Retry** | ìƒí™© ë¬´ê´€í•˜ê²Œ ë™ì¼ ì „ëžµ |

---

## ê¸°ì¡´ ì „ëžµê³¼ì˜ ê´€ê³„

### ë…ë¦½ì„±/ì‹œë„ˆì§€ ë¶„ì„

| ê¸°ì¡´ ì „ëžµ | ì¤‘ì²© ì—¬ë¶€ | ì‹œë„ˆì§€ ê°€ëŠ¥ì„± | ì„¤ëª… |
|-----------|-----------|---------------|------|
| **Memory-Augmented** | âŒ ë…ë¦½ | â­â­â­ ë†’ìŒ | Memory ì €ìž¥ ê²°ì •ì— confidence í™œìš© ê°€ëŠ¥ |
| **Error Recovery** | ðŸ”¶ ë¶€ë¶„ ì¤‘ì²© | â­â­â­ ë†’ìŒ | Recovery ì‹œì  ê²°ì •ì— uncertainty í™œìš© |
| **Cross-Domain Transfer** | âŒ ë…ë¦½ | â­â­ ì¤‘ê°„ | íŒ¨í„´ ì„ íƒì— confidence routing ì ìš© |
| **Adaptive Planning** | ðŸ”¶ ë¶€ë¶„ ì¤‘ì²© | â­â­â­ ë†’ìŒ | ê³„íš ë¶„ê¸°ì ì—ì„œ uncertainty ê¸°ë°˜ ê²°ì • |

### í•µì‹¬ ì°¨ë³„í™” í¬ì¸íŠ¸

```
ê¸°ì¡´ ì „ëžµ: "ë¬´ì—‡(What)ì„ í•  ê²ƒì¸ê°€"ì— ì§‘ì¤‘
ë³¸ ì—°êµ¬:   "ì–¼ë§ˆë‚˜ í™•ì‹ (How Certain)í•˜ëŠ”ê°€"ì— ì§‘ì¤‘ â†’ Orthogonal Dimension
```

**ì˜ˆìƒ ì‹œë„ˆì§€ íš¨ê³¼**:
- Error Recovery + Uncertainty: Recovery í•„ìš” ì‹œì  ì¡°ê¸° ê°ì§€ (+1-2%)
- Memory + Uncertainty: ì¤‘ìš” ì»¨í…ìŠ¤íŠ¸ ìš°ì„  ì €ìž¥ (+0.5-1%)

---

## í•µì‹¬ ì—°êµ¬ ê¸°ë°˜

### 1. Self-Certainty (arXiv 2502.18581, 2025.12)
- **í•µì‹¬**: LLM í™•ë¥  ë¶„í¬ë¡œ ì‘ë‹µ í’ˆì§ˆ í‰ê°€, reward model ë¶ˆí•„ìš”
- **ê²°ê³¼**: Best-of-Nì—ì„œ reward modelê³¼ ìœ ì‚¬ ì„±ëŠ¥
- **ì ìš© ê°€ëŠ¥ì„±**: â­â­â­ ì§ì ‘ ì ìš© ê°€ëŠ¥

### 2. Soft Self-Consistency (arXiv 2402.13212, 2024.02)
- **í•µì‹¬**: ì—°ì† ìŠ¤ì½”ì–´ë§ìœ¼ë¡œ majority voting ëŒ€ì²´
- **ê²°ê³¼**: ìƒ˜í”Œ 50% ê°ì†Œ, ì„±ê³µë¥  1.3-6.6% í–¥ìƒ
- **ì ìš© ê°€ëŠ¥ì„±**: â­â­â­ ì§ì ‘ ì ìš© ê°€ëŠ¥

### 3. Holistic Trajectory Calibration (OpenReview 2025.09)
- **í•µì‹¬**: ì—ì´ì „íŠ¸ ì „ì²´ ê¶¤ì ì—ì„œ ì‹ ë¢°ë„ ë³´ì •
- **ê²°ê³¼**: AUROC 20% í–¥ìƒ
- **ì ìš© ê°€ëŠ¥ì„±**: â­â­ ì•„í‚¤í…ì²˜ ìˆ˜ì • í•„ìš”

### 4. UniCR (arXiv 2509.01455, 2025.09)
- **í•µì‹¬**: ì‹ ë¢°ë„ + ê±°ë¶€(refusal) ê²°ì • í†µí•©
- **ê²°ê³¼**: ECE, Brier score ê°œì„ , hallucination ê°ì†Œ
- **ì ìš© ê°€ëŠ¥ì„±**: â­â­â­ ì§ì ‘ ì ìš© ê°€ëŠ¥

### 5. SAUP - Uncertainty Propagation (ACL 2025)
- **í•µì‹¬**: ë‹¤ë‹¨ê³„ ì˜ì‚¬ê²°ì •ì—ì„œ ë¶ˆí™•ì‹¤ì„± ì „íŒŒ ì¶”ì 
- **ê²°ê³¼**: AUROC 20% í–¥ìƒ
- **ì ìš© ê°€ëŠ¥ì„±**: â­â­ ë³µìž¡í•œ êµ¬í˜„ í•„ìš”

### 6. Self-Backtracking (arXiv 2502.04404, 2025.02)
- **í•µì‹¬**: LLMì´ ìžì²´ì ìœ¼ë¡œ ë°±íŠ¸ëž˜í‚¹ ì‹œì  ê²°ì •
- **ê²°ê³¼**: ì¶”ë¡  ì„±ëŠ¥ 40% í–¥ìƒ
- **ì ìš© ê°€ëŠ¥ì„±**: â­â­ Training í•„ìš”

---

## Research Questions

### RQ1: Best-of-N ìµœì í™” íš¨ê³¼
> **"Self-Certainty ê¸°ë°˜ ì‘ë‹µ ì„ íƒì´ Terminal-Bench íƒœìŠ¤í¬ì—ì„œ ê¸°ì¡´ majority voting ëŒ€ë¹„ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ì¸ê°€?"**

**ê²€ì¦ ë°©ë²•**:
- Terminal-Bench 89ê°œ íƒœìŠ¤í¬ ì¤‘ 20ê°œ ìƒ˜í”Œë§
- N=5 ì‘ë‹µ ìƒì„± í›„ 3ê°€ì§€ ë°©ë²• ë¹„êµ:
  1. Random selection (baseline)
  2. Majority voting (self-consistency)
  3. Self-Certainty scoring
- ì„±ê³µë¥  ë° í•„ìš” ìƒ˜í”Œ ìˆ˜ ì¸¡ì •

**ì˜ˆìƒ ê²°ê³¼**: +3-5% ì„±ê³µë¥  í–¥ìƒ, ìƒ˜í”Œ 30-50% ì ˆê°

---

### RQ2: Uncertainty-Based Action Router íš¨ê³¼
> **"ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ë™ì  ì „ëžµ ì„ íƒì´ ë‹¨ì¼ ì „ëžµ ëŒ€ë¹„ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ”ê°€?"**

**ê²€ì¦ ë°©ë²•**:
```python
def uncertainty_router(action_logprobs):
    entropy = calculate_entropy(action_logprobs)
    if entropy > HIGH_THRESHOLD:
        return "gather_more_info"  # ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
    elif entropy < LOW_THRESHOLD:
        return "execute_directly"   # ì§ì ‘ ì‹¤í–‰
    else:
        return "verify_then_execute"  # ê²€ì¦ í›„ ì‹¤í–‰
```
- Terminal-Bench debugging/file operation íƒœìŠ¤í¬ì—ì„œ í…ŒìŠ¤íŠ¸
- ê³ ì • ì „ëžµ vs ë™ì  ë¼ìš°íŒ… ë¹„êµ

**ì˜ˆìƒ ê²°ê³¼**: +2-3% ì„±ê³µë¥ , íŠ¹ížˆ ë³µìž¡í•œ íƒœìŠ¤í¬ì—ì„œ ê°œì„ 

---

### RQ3: Backtracking ê°œì„  íš¨ê³¼
> **"ì‹¤íŒ¨ ì‹œ logprobs ê¸°ë°˜ ëŒ€ì•ˆ íƒìƒ‰ì´ ë‹¨ìˆœ ìž¬ì‹œë„ ëŒ€ë¹„ íš¨ê³¼ì ì¸ê°€?"**

**ê²€ì¦ ë°©ë²•**:
```python
def alternative_exploration(failed_action, original_logprobs):
    # ì²« ë²ˆì§¸ ì„ íƒ ì‹¤íŒ¨ ì‹œ ë‘ ë²ˆì§¸ í™•ë¥  í›„ë³´ë¡œ ì‹œë„
    alternatives = sorted(original_logprobs, key=lambda x: x.prob, reverse=True)
    for alt in alternatives[1:3]:  # top-2, top-3 ì‹œë„
        if execute(alt.action).success:
            return alt.action
    return None
```
- ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ ë° ëŒ€ì•ˆ ì„±ê³µë¥  ì¸¡ì •

**ì˜ˆìƒ ê²°ê³¼**: Recovery rate +15-25% í–¥ìƒ

---

### RQ4: Terminal-Bench íŠ¹í™” ìµœì í™”
> **"Terminal/ì½”ë”© íƒœìŠ¤í¬ì—ì„œ ì–´ë–¤ uncertainty signalì´ ê°€ìž¥ íš¨ê³¼ì ì¸ê°€?"**

**ê²€ì¦ ë°©ë²•**:
- ë‹¤ì–‘í•œ uncertainty signal ë¹„êµ:
  1. Token-level entropy
  2. Sequence-level perplexity
  3. Semantic dispersion (UniCR ë°©ì‹)
  4. Command-specific confidence
- íƒœìŠ¤í¬ ìœ í˜•ë³„ (debugging, file ops, git ops) ì„±ëŠ¥ ì¸¡ì •

**ì˜ˆìƒ ê²°ê³¼**: Command-specific confidenceê°€ ê°€ìž¥ íš¨ê³¼ì  (íŠ¹ížˆ ìœ„í—˜ ëª…ë ¹ì–´)

---

## ìž ìž¬ì  ê°€ì¹˜

| ê°€ì¹˜ ìœ í˜• | ì˜ˆìƒ ìˆ˜ì¤€ | ê·¼ê±° |
|-----------|-----------|------|
| **ì„±ëŠ¥ í–¥ìƒ** | +5-8% (64.9% â†’ 70-73%) | ë…ë¦½ì  ê°œì„ , ê¸°ì¡´ ì „ëžµê³¼ ì‹œë„ˆì§€ |
| **ê³„ì‚° íš¨ìœ¨** | ìƒ˜í”Œ 30-50% ì ˆê° | Soft-SC ë…¼ë¬¸ ê²°ê³¼ ê¸°ë°˜ |
| **ì•ˆì „ì„± í–¥ìƒ** | ìœ„í—˜ ëª…ë ¹ì–´ ì‹¤í–‰ ì „ ê²€ì¦ | High uncertainty â†’ ì¶”ê°€ í™•ì¸ |
| **í•™ìˆ ì  ê°€ì¹˜** | ì¤‘ê°„ | Terminal Agent íŠ¹í™” ì—°êµ¬ ë¶€ìž¬ |
| **ìž¬ì‚¬ìš©ì„±** | ë†’ìŒ | ë‹¤ë¥¸ agent ì‹œìŠ¤í…œì— ë²”ìš© ì ìš© ê°€ëŠ¥ |

### ROI ë¶„ì„

```
íˆ¬ìž: 2-3ì£¼ êµ¬í˜„ + 1ì£¼ ì‹¤í—˜
ê¸°ëŒ€ ìˆ˜ìµ:
â”œâ”€â”€ Terminal-Bench ìˆœìœ„ ìƒìŠ¹ ê°€ëŠ¥ì„±: ë†’ìŒ
â”œâ”€â”€ ë…¼ë¬¸/ë¸”ë¡œê·¸ ë°œí–‰ ê°€ì¹˜: ì¤‘ê°„
â””â”€â”€ ë²”ìš© agent ê°œì„  ê¸°ë²•ìœ¼ë¡œ í™•ìž¥: ë†’ìŒ
```

---

## êµ¬í˜„ ë¡œë“œë§µ

### Phase 0: í™˜ê²½ ì„¸íŒ… + ê¸°ì´ˆ ë¶„ì„ (2-3ì¼)
- [ ] Harbor Framework í™˜ê²½ êµ¬ì¶•
- [ ] OpenAI/Anthropic API logprobs ì ‘ê·¼ ë°©ë²• í™•ì¸
- [ ] Terminal-Bench ìƒ˜í”Œ íƒœìŠ¤í¬ 20ê°œ ì„ ì •
- [ ] ê¸°ì¡´ Factory Droid ì‹¤íŒ¨ íŒ¨í„´ ë¶„ë¥˜

### Phase 1: Self-Certainty Best-of-N (1ì£¼)
```python
# í•µì‹¬ êµ¬í˜„
def self_certainty_score(response, model):
    """Self-Certainty ë…¼ë¬¸ ê¸°ë°˜ êµ¬í˜„"""
    tokens = tokenize(response)
    logprobs = model.get_logprobs(response)
    
    # ë¶„í¬ ì§‘ì¤‘ë„ ì¸¡ì •
    certainty = -sum(p * log(p) for p in logprobs) / len(tokens)
    return certainty

def best_of_n_selection(responses, model):
    scores = [self_certainty_score(r, model) for r in responses]
    return responses[argmax(scores)]
```
- [ ] Self-Certainty ìŠ¤ì½”ì–´ë§ êµ¬í˜„
- [ ] N=3,5,7 ë¹„êµ ì‹¤í—˜
- [ ] Terminal-Bench ìƒ˜í”Œ ì œì¶œ â†’ **+3% ì´ìƒ í™•ì¸**
- **Go/No-Go**: +2% ë¯¸ë§Œì´ë©´ Phase 2ë¡œ ì¦‰ì‹œ ì „í™˜

### Phase 2: Uncertainty-Based Router (1ì£¼)
```python
# í•µì‹¬ êµ¬í˜„
class UncertaintyRouter:
    def __init__(self, high_thresh=2.0, low_thresh=0.5):
        self.high_thresh = high_thresh
        self.low_thresh = low_thresh
    
    def route(self, action_logprobs):
        entropy = self.calculate_entropy(action_logprobs)
        
        if entropy > self.high_thresh:
            return Strategy.GATHER_INFO
        elif entropy < self.low_thresh:
            return Strategy.EXECUTE
        else:
            return Strategy.VERIFY_FIRST
```
- [ ] Entropy ê¸°ë°˜ ë¼ìš°í„° êµ¬í˜„
- [ ] íƒœìŠ¤í¬ ìœ í˜•ë³„ threshold íŠœë‹
- [ ] Terminal-Bench ì œì¶œ â†’ **ëˆ„ì  +5% ì´ìƒ í™•ì¸**

### Phase 3: Alternative Exploration (1ì£¼)
```python
# í•µì‹¬ êµ¬í˜„
class AlternativeExplorer:
    def on_failure(self, failed_action, original_logprobs):
        """ì‹¤íŒ¨ ì‹œ í™•ë¥  ê¸°ë°˜ ëŒ€ì•ˆ íƒìƒ‰"""
        alternatives = self.get_top_k_alternatives(original_logprobs, k=3)
        
        for alt in alternatives:
            if alt.action != failed_action:
                result = self.try_action(alt.action)
                if result.success:
                    return result
        
        return self.fallback_strategy()
```
- [ ] Logprobs ê¸°ë°˜ ëŒ€ì•ˆ ì¶”ì¶œ êµ¬í˜„
- [ ] ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë³„ ëŒ€ì•ˆ ì„±ê³µë¥  ë¶„ì„
- [ ] Terminal-Bench ì œì¶œ â†’ **ëˆ„ì  +7% ì´ìƒ í™•ì¸**

### Phase 4: í†µí•© + ìµœì í™” (3-5ì¼)
- [ ] ê¸°ì¡´ ì „ëžµ (Memory, Error Recovery)ê³¼ í†µí•© í…ŒìŠ¤íŠ¸
- [ ] Hyperparameter ìµœì í™”
- [ ] ìµœì¢… Terminal-Bench ì œì¶œ
- [ ] ê²°ê³¼ ë¬¸ì„œí™”

---

## ëŒ€ì•ˆ ì „ëžµ (Plan B/C)

| Plan | ì¡°ê±´ | ì „ëžµ |
|------|------|------|
| **Plan B** | Phase 1ì—ì„œ +2% ë¯¸ë‹¬ | UniCR ë°©ì‹ìœ¼ë¡œ ì „í™˜ (refusal ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€) |
| **Plan C** | íŠ¹ì • íƒœìŠ¤í¬ë§Œ íš¨ê³¼ | í•´ë‹¹ íƒœìŠ¤í¬ ìœ í˜• íŠ¹í™” (ì˜ˆ: debugging only) |
| **Plan D** | Logprobs ì ‘ê·¼ ì œí•œ | Verbalized confidence ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ |

---

## í•µì‹¬ ì§ˆë¬¸ (ë‹¤ìŒ ë‹¨ê³„ìš©)

1. **API ì ‘ê·¼ì„±**: OpenAI/Anthropic APIì—ì„œ logprobsë¥¼ ì–´ë–¤ granularityë¡œ ì–»ì„ ìˆ˜ ìžˆëŠ”ê°€?
2. **Latency ì˜í–¥**: Uncertainty ê³„ì‚° ì¶”ê°€ ì‹œ ì‘ë‹µ ì‹œê°„ ì¦ê°€ëŠ” ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?
3. **í„°ë¯¸ë„ íŠ¹í™”**: ì½”ë”©/í„°ë¯¸ë„ ëª…ë ¹ì–´ì—ì„œ ê°€ìž¥ informativeí•œ uncertainty signalì€ ë¬´ì—‡ì¸ê°€?

---

## ë¦¬ì„œì¹˜ ë‚œì´ë„: ì¤‘ê°„
- í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì€ ê¸°ì¡´ ë…¼ë¬¸ì—ì„œ ê²€ì¦ë¨
- Terminal Agent íŠ¹í™” ì ìš©ì€ ìƒˆë¡œìš´ ì‹œë„
- Logprobs ì ‘ê·¼ ë°©ë²•ì— ë”°ë¼ ë‚œì´ë„ ë³€ë™

## ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3-4ì£¼
- Phase 0: 2-3ì¼
- Phase 1-3: ê° 1ì£¼
- Phase 4: 3-5ì¼

---

## ì°¸ê³  ë¬¸í—Œ

### í•µì‹¬ ì°¸ì¡°
1. [Self-Certainty for Best-of-N](https://arxiv.org/abs/2502.18581) - Best-of-N ìµœì í™” ê¸°ë²•
2. [Soft Self-Consistency](https://arxiv.org/abs/2402.13212) - ì—°ì† ìŠ¤ì½”ì–´ë§ ë°©ë²•
3. [UniCR](https://arxiv.org/abs/2509.01455) - ì‹ ë¢°ë„ + ê±°ë¶€ í†µí•©
4. [SAUP](https://aclanthology.org/2025.acl-long.302/) - ë‹¤ë‹¨ê³„ ë¶ˆí™•ì‹¤ì„± ì „íŒŒ
5. [Holistic Trajectory Calibration](https://openreview.net/forum?id=6YMFsGFabM) - ê¶¤ì  ì‹ ë¢°ë„ ë³´ì •

### ì¶”ê°€ ì°¸ì¡°
6. [Self-Backtracking](https://arxiv.org/abs/2502.04404) - ìžì²´ ë°±íŠ¸ëž˜í‚¹
7. [Tree Search for LM Agents](https://openreview.net/forum?id=kpL66Mvd2a) - íŠ¸ë¦¬ íƒìƒ‰ ê¸°ë²•
8. [CARGO Routing](https://arxiv.org/html/2509.14899v1) - ì‹ ë¢°ë„ ê¸°ë°˜ ë¼ìš°íŒ…

---

*Generated by research-topic-explorer | 2026-01-07*
